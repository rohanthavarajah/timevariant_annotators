{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Use the model trace to reconstruct the main outputs of the paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents \n",
    "\n",
    "1. <a href='#goldstandard'>Import gold standard.</a>\n",
    "2. <a href='#baseline'>Construct majority voting baseline</a>\n",
    "3. <a href='#validationhard'>Get validation error on difficult posts</a>\n",
    "3. <a href='#validationeasy'>Get validation error on easy posts</a>\n",
    "3. <a href='#paths'>Plot skill paths</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goldstandard'></a>\n",
    "#### 1. Import gold standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In two waves, we collected all posts for which the model and majority voting conflicted and passed them to a Tribe employee to evaluate ground truth.\n",
    "\n",
    "\n",
    "* First we import those gold standard cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import two waves of Tribe manual verification\n",
    "ground_truth1 = pd.read_csv(os.path.join(\"input\", \"Rohan Mturk Conflicts 2017-12-04.csv\"))\n",
    "ground_truth2 = pd.read_csv(os.path.join(\"input\", \"Rohan Mturk Conflicts 2017-12-22.csv\"))\n",
    "ground_truth2 = ground_truth2.rename(columns={\"Tribe Decision\":\"Tribe decision\"})\n",
    "ground_truth = ground_truth1.append(ground_truth2, sort=False)\n",
    "# keep columsn of interest\n",
    "ground_truth = ground_truth[[\"text\",\"Tribe decision\"]]\n",
    "ground_truth = ground_truth.rename(columns={\"Tribe decision\":\"z_obs\"})\n",
    "# keep unambiguous cases\n",
    "ground_truth = ground_truth[ground_truth[\"z_obs\"].isin([\"0\",\"1\"])]\n",
    "ground_truth[\"z_obs\"] = ground_truth[\"z_obs\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='baseline'></a>\n",
    "#### 2. Construct majority voting baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We lift cleaning steps from **tribe_010218.py**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accessory(tribe_csvs, condense_repeat_votes=True, keep_prolific_cut=20):\n",
    "    # import\n",
    "    df_brands = [pd.read_csv(csv) for csv in tribe_csvs]\n",
    "    \n",
    "    # merge\n",
    "    tribe_df = pd.concat(df_brands)\n",
    "    tribe_df = tribe_df.loc[tribe_df[\"mturker\"]==True,:]\n",
    "\n",
    "    # deal with brand ambiguity\n",
    "    tribe_df[\"post_hash\"] = tribe_df[\"post_hash\"].astype(str) + \"_\" + tribe_df[\"brand_id\"].astype(str)\n",
    "    text_lkup = tribe_df[[\"post_hash\",\"text\"]].drop_duplicates()\n",
    "    \n",
    "    # condense\n",
    "    if condense_repeat_votes==True:\n",
    "        rows_before = tribe_df.shape[0]\n",
    "        tribe_df = tribe_df.groupby([\"brand_id\",\"worker_id\",\"post_hash\"]).mean().reset_index()\n",
    "        # hard cases\n",
    "        hard_cases_df = tribe_df.loc[tribe_df[\"answer\"]==0.5,:]\n",
    "        # easy cases\n",
    "        tribe_df = tribe_df.loc[tribe_df[\"answer\"]!=0.5,:]\n",
    "        tribe_df[\"answer\"] = 1*(tribe_df[\"answer\"]>0.5)\n",
    "        hard_cases_df[\"answer\"] = 1\n",
    "        tribe_df = pd.concat([tribe_df, hard_cases_df])\n",
    "        hard_cases_df[\"answer\"] = 0\n",
    "        tribe_df = pd.concat([tribe_df, hard_cases_df])\n",
    "        print(\"rows dropped due to condensing = %i\" % (rows_before-tribe_df.shape[0]))\n",
    "    \n",
    "    # get workers with more than 20 labels\n",
    "    workload = tribe_df.groupby(\"worker_id\").count().reset_index()\n",
    "    worker_subset = workload[workload[\"post_hash\"]>keep_prolific_cut].worker_id.values\n",
    "    rows_before = tribe_df.shape[0]\n",
    "    tribe_df = tribe_df[tribe_df.worker_id.isin(worker_subset)]\n",
    "    print(\"rows dropped due to non prolific worker = %i\" % (rows_before-tribe_df.shape[0]))\n",
    "\n",
    "    tribe_df[\"r_maj\"] = tribe_df[\"answer\"]*1\n",
    "    r_maj = tribe_df \\\n",
    "        .groupby([\"post_hash\",\"brand_id\"]) \\\n",
    "        .mean()[\"r_maj\"] \\\n",
    "        .reset_index()\n",
    "\n",
    "    worker_ct = tribe_df \\\n",
    "        .groupby([\"post_hash\",\"brand_id\"]) \\\n",
    "        .count()[\"answer\"] \\\n",
    "        .reset_index().rename(columns={\"answer\":\"worker_ct\"})\n",
    "        \n",
    "    model_decision_df = tribe_df[[\"post_hash\",\"model_decision\"]].drop_duplicates()\n",
    "    \n",
    "    accessory_df = r_maj.merge(worker_ct, on=[\"post_hash\",\"brand_id\"], indicator=True)\n",
    "    assert np.mean(accessory_df[\"_merge\"]==\"both\")==1\n",
    "    del accessory_df[\"_merge\"]\n",
    "    \n",
    "    brand_lookup = pd.DataFrame({\n",
    "        \"brand_id\":[18795,11977,13584,18792,15004,14937,15336],\n",
    "        \"brand_name\":[\"braun\",\"mac\",\"mufe\",\"kate\",\"patagonia\",\"ross\",\"simple\"]\n",
    "    })\n",
    "    accessory_df = accessory_df.merge(brand_lookup, on=[\"brand_id\"], indicator=True)\n",
    "    assert np.mean(accessory_df[\"_merge\"]==\"both\")==1\n",
    "    del accessory_df[\"_merge\"]\n",
    "    \n",
    "    accessory_df = accessory_df.merge(text_lkup, on=[\"post_hash\"], indicator=True)\n",
    "    assert np.mean(accessory_df[\"_merge\"]==\"both\")==1\n",
    "    del accessory_df[\"_merge\"]\n",
    " \n",
    "    accessory_df = accessory_df.merge(model_decision_df, on=[\"post_hash\"], indicator=True)\n",
    "    assert np.mean(accessory_df[\"_merge\"]==\"both\")==1\n",
    "    del accessory_df[\"_merge\"]\n",
    "    \n",
    "    return accessory_df[[\"post_hash\",\"r_maj\",\"worker_ct\",\"brand_name\",\"text\",\"model_decision\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows dropped due to condensing = 5057\n",
      "rows dropped due to non prolific worker = 3953\n"
     ]
    }
   ],
   "source": [
    "tribe_csvs = [\n",
    "    os.path.join(\"input\",\"rohan_11977_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_13584_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_14937_1513051907.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_15004_1513051907.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_15336_1513051907.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_17231_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_17334_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_18792_1513051907.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_18795_1513051907.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19123_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19141_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19154_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19321_1513051779.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19491_1513050263.csv\"),\n",
    "    os.path.join(\"input\",\"rohan_19491_1513051779.csv\"),\n",
    "]\n",
    "\n",
    "accessory_df = get_accessory(tribe_csvs, condense_repeat_votes=True, keep_prolific_cut=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validationhard'></a>\n",
    "#### 3. Get validation error on difficult posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get inferred label from annotation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(pickle_in, suffix):\n",
    "    data = pd.read_pickle(pickle_in)\n",
    "    z_obs = data[\"z_obs\"]\n",
    "    trace = data[\"trace\"]\n",
    "    jj_transformer = data[\"jj_transformer\"]\n",
    "    z_init = data[\"z_init\"]\n",
    "    kk_transformer = data[\"kk_transformer\"]\n",
    "    ii_transformer = data[\"ii_transformer\"]\n",
    "    \n",
    "    z_inferred = np.array(z_obs, dtype=float)\n",
    "    z_inferred[np.where(z_obs==-999)[0]] = np.mean(trace[\"z_missing\"], axis=0)\n",
    "        \n",
    "    pred_df = pd.DataFrame({\n",
    "        \"post_hash\":ii_transformer.index,\n",
    "        \"z_inferred_\"+suffix:z_inferred,\n",
    "        \"flag_hashtag\":data[\"flag_hashtag\"]})\n",
    "    pred_df[\"post_hash\"] = pred_df[\"post_hash\"].astype(str)\n",
    "\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = {\"pickle_in\":os.path.join(\"output\",\"trace_cfg1.pkl\"), \"suffix\":\"cfg1\"}\n",
    "cfg3 = {\"pickle_in\":os.path.join(\"output\",\"trace_cfg3.pkl\"), \"suffix\":\"cfg3\"}\n",
    "cfg11 = {\"pickle_in\":os.path.join(\"output\",\"trace_cfg11.pkl\"), \"suffix\":\"cfg11\"}\n",
    "cfg12 = {\"pickle_in\":os.path.join(\"output\",\"trace_cfg12.pkl\"), \"suffix\":\"cfg12\"}\n",
    "\n",
    "cfg_list = [\n",
    "    cfg1, \n",
    "    cfg3, \n",
    "    cfg11,\n",
    "    cfg12,\n",
    "]\n",
    "\n",
    "for ind, cfg in enumerate(cfg_list):\n",
    "    pred_df = get_predictions(**cfg)\n",
    "    accessory_df = accessory_df.merge(pred_df, on=[\"post_hash\"], indicator=True)\n",
    "    assert np.mean(accessory_df[\"_merge\"]==\"both\")==1\n",
    "    del accessory_df[\"_merge\"]\n",
    "    if ind!=len(cfg_list)-1:\n",
    "        del accessory_df[\"flag_hashtag\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* collect cases when majority voting and model conflict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_inferred_list = [\n",
    "    \"z_inferred_cfg1\", \n",
    "    \"z_inferred_cfg3\", \n",
    "    \"z_inferred_cfg11\",\n",
    "    \"z_inferred_cfg12\",    \n",
    "]\n",
    "\n",
    "accessory_df[\"conflict\"] = \"none\"\n",
    "accessory_df.loc[accessory_df[\"r_maj\"]==0.5,\"conflict\"] = \"50/50 split\"\n",
    "for var in z_inferred_list:\n",
    "    accessory_df.loc[((accessory_df[\"r_maj\"]<0.5) & (accessory_df[var]>0.5)),\"conflict\"] = \"contradict majority\"\n",
    "    accessory_df.loc[((accessory_df[\"r_maj\"]>0.5) & (accessory_df[var]<0.5)),\"conflict\"] = \"contradict majority\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* list accuracy on difficult cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy - difficult cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z_inferred_cfg1</td>\n",
       "      <td>0.664516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z_inferred_cfg3</td>\n",
       "      <td>0.840237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z_inferred_cfg11</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z_inferred_cfg12</td>\n",
       "      <td>0.615942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             config  accuracy - difficult cases\n",
       "0   z_inferred_cfg1                    0.664516\n",
       "1   z_inferred_cfg3                    0.840237\n",
       "2  z_inferred_cfg11                    0.833333\n",
       "3  z_inferred_cfg12                    0.615942"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = ground_truth.merge(accessory_df, on=[\"text\"], how=\"left\", indicator=True)\n",
    "conf_df = validation_df[validation_df[\"r_maj\"]!=0.5]\n",
    "\n",
    "conf_acc = []\n",
    "for cfg in z_inferred_list:\n",
    "    tmp = conf_df[1*(conf_df[cfg]>0.5) != 1*(conf_df[\"r_maj\"]>0.5)]\n",
    "    conf_acc.append(np.mean(1*(tmp[cfg]>0.5) == tmp[\"z_obs\"]))\n",
    "pd.DataFrame(list(zip(z_inferred_list, conf_acc)), columns=[\"config\", \"accuracy - difficult cases\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='validationeasy'></a>\n",
    "#### 4. Get validation error on easy posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat for posts which Tribe employees had initially already labeled. This constitutes the \"easy\" validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows dropped due to condensing = 5057\n",
      "rows dropped due to non prolific worker = 3953\n"
     ]
    }
   ],
   "source": [
    "validation_df = pd.read_csv(os.path.join(\"output\",\"validation_df.csv\"), index_col=0)\n",
    "accessory_df = get_accessory(tribe_csvs, condense_repeat_votes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, cfg in enumerate(cfg_list):\n",
    "    pred_df = get_predictions(**cfg)\n",
    "    validation_df = validation_df.merge(pred_df, on=[\"post_hash\"], indicator=True)\n",
    "    assert np.mean(validation_df[\"_merge\"]==\"both\")==1\n",
    "    del validation_df[\"_merge\"]\n",
    "    if ind!=len(cfg_list)-1:\n",
    "        del validation_df[\"flag_hashtag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config</th>\n",
       "      <th>accuracy - easy cases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z_inferred_cfg1</td>\n",
       "      <td>0.823171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z_inferred_cfg3</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z_inferred_cfg11</td>\n",
       "      <td>0.914634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z_inferred_cfg12</td>\n",
       "      <td>0.792683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             config  accuracy - easy cases\n",
       "0   z_inferred_cfg1               0.823171\n",
       "1   z_inferred_cfg3               0.914634\n",
       "2  z_inferred_cfg11               0.914634\n",
       "3  z_inferred_cfg12               0.792683"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = validation_df.merge(accessory_df, on=[\"post_hash\"])\n",
    "conf_df = validation_df[validation_df[\"r_maj\"]!=0.5]\n",
    "\n",
    "conf_acc = []\n",
    "for cfg in z_inferred_list:\n",
    "    conf_acc.append(np.mean(1*(conf_df[cfg]>0.5) == conf_df[\"z_obs\"]))\n",
    "pd.DataFrame(list(zip(z_inferred_list, conf_acc)), columns=[\"config\", \"accuracy - easy cases\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='paths'></a>\n",
    "#### 5. Plot paths of annotator skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = os.path.join(\"output\",\"trace_cfg3.pkl\")\n",
    "data = pd.read_pickle(pickle_in)\n",
    "J = len(data[\"jj_transformer\"])\n",
    "trace = data[\"trace\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get most prolific workers to plot\n",
    "Tj = []\n",
    "for j in range(J):\n",
    "    Tj.append(trace[\"alpha_walk0\"+str(j)].shape[1])\n",
    "\n",
    "volatility_pe = np.mean(trace[\"volatility0\"], axis=0)\n",
    "rank_df = pd.DataFrame({\"volatility_pe\":volatility_pe, \"Tj\":Tj}).sort_values(by=[\"Tj\"], ascending=False)\n",
    "most_prolific = rank_df.index[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This output of this cell has been cleared for the sake of confidentiality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "for i, j in enumerate(most_prolific):\n",
    "    # path\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.fill_between(x=range(trace[\"alpha_walk0\"+str(j)].shape[1]), \n",
    "                    y1=np.mean(1/(1+np.exp(-1*trace[\"alpha_walk0\"+str(j)])), axis=0) + np.std(1/(1+np.exp(-1*trace[\"alpha_walk0\"+str(j)])), axis=0),\n",
    "                    y2=np.mean(1/(1+np.exp(-1*trace[\"alpha_walk0\"+str(j)])), axis=0) - np.std(1/(1+np.exp(-1*trace[\"alpha_walk0\"+str(j)])), axis=0),\n",
    "                    alpha=0.3,\n",
    "                    lw=0,\n",
    "                    color='blue'\n",
    "                    )\n",
    "    plt.plot(1/(1+np.exp(-1*np.mean(trace[\"alpha_walk0\"+str(j)], axis=0))), color=\"blue\", label='credibility when z=0');\n",
    "    plt.fill_between(x=range(trace[\"alpha_walk1\"+str(j)].shape[1]), \n",
    "                    y1=np.mean(1/(1+np.exp(-1*trace[\"alpha_walk1\"+str(j)])), axis=0) + np.std(1/(1+np.exp(-1*trace[\"alpha_walk1\"+str(j)])), axis=0),\n",
    "                    y2=np.mean(1/(1+np.exp(-1*trace[\"alpha_walk1\"+str(j)])), axis=0) - np.std(1/(1+np.exp(-1*trace[\"alpha_walk1\"+str(j)])), axis=0),\n",
    "                    alpha=0.3,\n",
    "                    lw=0,\n",
    "                    color='purple'\n",
    "                    )\n",
    "    plt.plot(1/(1+np.exp(-1*np.mean(trace[\"alpha_walk1\"+str(j)], axis=0))), color=\"purple\", label='credibility when z=1');\n",
    "    plt.ylim([0,1])\n",
    "    if i<5:\n",
    "        plt.xlim([0,400])\n",
    "        plt.xticks([])\n",
    "    else:\n",
    "        plt.xlim([0,400])\n",
    "        plt.xticks([0,200,400])\n",
    "    if i!=0 and i!=5:\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        plt.yticks([0,0.5,1])\n",
    "    plt.axhline(y=0.5, ls='--', lw=0.5, color='gray')\n",
    "    if i==3:\n",
    "        plt.legend(ncol=2, bbox_to_anchor=(1.2,-1.7))\n",
    "    if i==0:\n",
    "        plt.text(-170, -0.1, 'Credibility', va='center', rotation='vertical', fontsize=12)\n",
    "    if i==7:\n",
    "        plt.xlabel(\"Objects Labeled (20s)\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc3",
   "language": "python",
   "name": "pymc3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
